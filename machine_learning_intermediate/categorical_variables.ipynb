{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75fd309",
   "metadata": {},
   "source": [
    "# Intermediate Machine Learning Micro \n",
    "\n",
    "An expansion on the concepts and methods used in the intro to machine learning micro course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b553d7a3",
   "metadata": {},
   "source": [
    "## Categorical Variables\n",
    "\n",
    "Categorical values are ones with a set of predefined options. Things like car brands (Honda, Ford, Toyota, etc.) or entries to dropdown boxes (in progress, not started, etc.) are categorical variables. These will lead to errors in most machine learning models by default if fed in raw due to the fact they are strings. We will look at 3 approaches to dealing with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954afee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and set up training / validation sets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "MELBOURNE_DATA_PATH = '..\\\\data\\\\melb_data.csv'\n",
    "melb_data = pd.read_csv(MELBOURNE_DATA_PATH)\n",
    "\n",
    "y = melb_data.Price\n",
    "X = melb_data.drop(['Price'], axis=1)\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# Drop columns with missing values (simplest approach)\n",
    "cols_with_missing = [col for col in X_train_full.columns if X_train_full[col].isnull().any()] \n",
    "X_train_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_valid_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c414f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define funciton to return MAE score for the data\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def score_dataset(X_train, X_val, y_train, y_val) -> float:\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "    return mean_absolute_error(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d08f7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['Type', 'Method', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "# Get a list of categorical variables\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(f'Categorical variables:\\n{object_cols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b5d69",
   "metadata": {},
   "source": [
    "### Approach 1: Drop Categorical Variables\n",
    "\n",
    "Simply dropping the data that consists of categorical values can be an effetive approach if the data is not meaningful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5e49b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from approach #1 (drop categorical variables): 183550.22137772635\n"
     ]
    }
   ],
   "source": [
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "\n",
    "print(f'MAE from approach #1 (drop categorical variables): {score_dataset(drop_X_train, drop_X_valid, y_train, y_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb9b04b",
   "metadata": {},
   "source": [
    "### Approach 2: Ordinal Encoding\n",
    "\n",
    "Replacing each of the unique values with a unique integer. for example in a survey where one of the questions can be answered \"Never\", \"Rarely\", \"Most Days\", or \"Always\", each value can be assigned a number 0, 1, 2, 3. This approach is called \"ordinal encoding\".\n",
    "\n",
    "Works especially well for data where the numbers corolate to something in the data like in this example. may not work as well with something like car brands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeae2b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from approach #2 (Ordinal Encoding): 175062.2967599411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Make a copy to avoid changing original data\n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "\n",
    "# Apply ordinal encoder to each column with categorical data\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
    "label_X_valid[object_cols] = ordinal_encoder.fit_transform(X_valid[object_cols])\n",
    "\n",
    "print(f'MAE from approach #2 (Ordinal Encoding): {score_dataset(label_X_train, label_X_valid, y_train, y_valid)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c26648",
   "metadata": {},
   "source": [
    "This is a common approach that is simpler than providing custom labels; however, we can expect an additional boost in performance if we provide better-informed labels for all ordinal variables.\n",
    "\n",
    "When using Ordinal Encoding be sure to check the unique values in both the training and validation data. sometimes a value will appear only in the training or only in the validation and this will cause and error. It willl work if the trianing data has all of the categories that show up in the validation data but if the validation data has a new value then theres a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce7f7c",
   "metadata": {},
   "source": [
    "### Approach 3: One-Hot Encoding\n",
    "\n",
    "Create a new column for each of the categories, a 1 is placed in the new column related to the data that was originally in the row and a zero for each of the categories not represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaf2d5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from approach #3 (One-Hot Encoding): 176703.63810751104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply on-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "# NOTE: handle_unknown describes the behavior of the encoder if it encounters values not in the training data\n",
    "# NOTE: sparese tells teh encoder if we want it returned as sparse matrix (True) or numpy array (False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "# One-hot encoding removed index\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Remove categorical columns (to be replaced by one-hot encoded)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns  to numberical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "# Ensure all columns have string type\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "\n",
    "print(f'MAE from approach #3 (One-Hot Encoding): {score_dataset(OH_X_train, OH_X_valid, y_train, y_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b45ee8",
   "metadata": {},
   "source": [
    "One hot encoding typically performs best followed by Ordinal encoding with dropping data generally performing worst."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
